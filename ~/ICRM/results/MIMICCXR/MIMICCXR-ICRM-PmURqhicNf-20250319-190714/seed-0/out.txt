=> Environment:
	Python: 3.8.20
	PyTorch: 2.0.0+cu117
	Torchvision: 0.15.0+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.4
	PIL: 10.4.0
=> Using small batch size (1) for testing
=> Using small context length (3) for testing
=> HParams:
	additonal_metrics: ['worst_group', 'average']
	batch_size: 1
	beta1: 0.5
	context_length: 3
	data_augmentation: True
	densenet121: False
	device: cuda
	freeze_bn: 1
	is_iid_tr: 0
	is_parallel: True
	is_supervised: 0
	is_transformer: 0
	loss: cross_entropy
	lr: 0.0001
	metrics: ['acc']
	n_embd: 132
	n_head: 3
	n_layer: 12
	n_sampled_tasks: 0
	nonlinear_classifier: False
	num_features: 3
	optimizer_name: Adam
	output_dir: ~/ICRM/results/MIMICCXR/MIMICCXR-ICRM-PmURqhicNf-20250319-190714/seed-0
	overall_seed: 0
	print_last: 1
	resnet18: False
	resnet_dropout: 0
	terminal_command: main.py --dataset MIMICCXR --algorithm ICRM --small_batch --small_context
	test_batch_size: 1
	trial_seed: 0
	weight_decay: 0.0
=> Seed of the run set to 0
=> Creating dataset object...
Training on 8 groups, validating on 1 groups, testing on 3 groups
=> n training domains:  8
=> Smallest domain:  27
=> Largest domain:  244 

=> n validation domains:  1
=> Smallest domain:  42
=> Largest domain:  42 

=> n testing domains:  3
=> Smallest domain:  49
=> Largest domain:  192 

=> Dataset object created successfully
=> Creating training data loaders...
=> Number of environments: 8
=> Environment sizes: [244, 70, 41, 27, 55, 39, 85, 77]
=> Batch size: 1
=> Number of workers: 8
=> All training loaders created successfully
=> Creating validation data loaders...
=> Validation loaders created successfully
instantiating algorithm
=> Training ResNet architecture...
=> Training ResNet with frozen batch norm...
=> Initializing a GPT2 Transformer...
=> Using data parallel
training
=> Checkpointing based on acc(e-0)
Traceback (most recent call last):
  File "main.py", line 219, in <module>
    step_metrics = algorithm.update(minibatches_device)
  File "/data/healthy-ml/scratch/odahleh/mimic-mil/algorithms.py", line 88, in update
    out = self.predict(x, y)
  File "/data/healthy-ml/scratch/odahleh/mimic-mil/algorithms.py", line 299, in predict
    outputs = self.classifier((x, y, None, past_key_values))
  File "/data/healthy-ml/scratch/odahleh/anaconda3/envs/icrm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/healthy-ml/scratch/odahleh/mimic-mil/networks.py", line 196, in forward
    outputs = self._backbone(inputs_embeds=embeds, past_key_values=past_key_values)
  File "/data/healthy-ml/scratch/odahleh/anaconda3/envs/icrm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/healthy-ml/scratch/odahleh/anaconda3/envs/icrm/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 1132, in forward
    outputs = block(
  File "/data/healthy-ml/scratch/odahleh/anaconda3/envs/icrm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/healthy-ml/scratch/odahleh/anaconda3/envs/icrm/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 615, in forward
    attn_outputs = self.attn(
  File "/data/healthy-ml/scratch/odahleh/anaconda3/envs/icrm/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/healthy-ml/scratch/odahleh/anaconda3/envs/icrm/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 332, in forward
    attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)
  File "/data/healthy-ml/scratch/odahleh/anaconda3/envs/icrm/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py", line 203, in _attn
    attn_weights = torch.where(causal_mask, attn_weights.to(attn_weights.dtype), mask_value)
RuntimeError: The size of tensor a (3) must match the size of tensor b (10) at non-singleton dimension 3
